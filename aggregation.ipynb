{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import datetime\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Tesla_Comments_Filtered_Analyzed.csv', delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TSLA = pd.read_csv('TSLA (3).csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 251 entries, 0 to 250\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Date       251 non-null    object \n",
      " 1   Open       251 non-null    float64\n",
      " 2   High       251 non-null    float64\n",
      " 3   Low        251 non-null    float64\n",
      " 4   Close      251 non-null    float64\n",
      " 5   Adj Close  251 non-null    float64\n",
      " 6   Volume     251 non-null    int64  \n",
      "dtypes: float64(5), int64(1), object(1)\n",
      "memory usage: 13.9+ KB\n"
     ]
    }
   ],
   "source": [
    "TSLA.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maart\\AppData\\Local\\Temp\\ipykernel_13812\\1425919129.py:2: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  TSLA['Date'] = pd.to_datetime(TSLA['Date'])\n"
     ]
    }
   ],
   "source": [
    "#Turns out it is not so we convert it \n",
    "TSLA['Date'] = pd.to_datetime(TSLA['Date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TSLA['date'] = TSLA['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>id</th>\n",
       "      <th>body</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>date</th>\n",
       "      <th>emotion</th>\n",
       "      <th>probas</th>\n",
       "      <th>reg_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TeslaMotors</td>\n",
       "      <td>hqqtbh2</td>\n",
       "      <td>If help is needed, use our stickied support th...</td>\n",
       "      <td>1.640994e+09</td>\n",
       "      <td>t3_rt6fwg</td>\n",
       "      <td>2022-01-01 00:46:50</td>\n",
       "      <td>AnalyzerOutput(output=NEU, probas={NEU: 0.832,...</td>\n",
       "      <td>[('NEG', 0.0038293171674013138), ('NEU', 0.832...</td>\n",
       "      <td>0.159910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TeslaMotors</td>\n",
       "      <td>hqqtz7i</td>\n",
       "      <td>Requirements: \\n\\n• Fits under the aero cover ...</td>\n",
       "      <td>1.640995e+09</td>\n",
       "      <td>t3_rt6j33</td>\n",
       "      <td>2022-01-01 00:51:46</td>\n",
       "      <td>AnalyzerOutput(output=NEU, probas={NEU: 0.872,...</td>\n",
       "      <td>[('NEG', 0.11134149879217148), ('NEU', 0.87199...</td>\n",
       "      <td>-0.094674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TeslaMotors</td>\n",
       "      <td>hqqu7z3</td>\n",
       "      <td>Photo credit @rkaplan1 on Twitter</td>\n",
       "      <td>1.640995e+09</td>\n",
       "      <td>t3_rt6kex</td>\n",
       "      <td>2022-01-01 00:53:37</td>\n",
       "      <td>AnalyzerOutput(output=NEU, probas={NEU: 0.922,...</td>\n",
       "      <td>[('NEG', 0.003630931256338954), ('NEU', 0.9218...</td>\n",
       "      <td>0.070899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TeslaMotors</td>\n",
       "      <td>hqqxko8</td>\n",
       "      <td>I've wanted an Apple MagSafe charger in my cen...</td>\n",
       "      <td>1.640996e+09</td>\n",
       "      <td>t3_rt72vs</td>\n",
       "      <td>2022-01-01 01:20:13</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.785,...</td>\n",
       "      <td>[('NEG', 0.784606397151947), ('NEU', 0.2061541...</td>\n",
       "      <td>-0.775367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TeslaMotors</td>\n",
       "      <td>hqr8kka</td>\n",
       "      <td>I see you set your temperature to: NICE.</td>\n",
       "      <td>1.641002e+09</td>\n",
       "      <td>t3_rt8o5j</td>\n",
       "      <td>2022-01-01 02:47:11</td>\n",
       "      <td>AnalyzerOutput(output=POS, probas={POS: 0.675,...</td>\n",
       "      <td>[('NEG', 0.00296275457367301), ('NEU', 0.32224...</td>\n",
       "      <td>0.671825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165105</th>\n",
       "      <td>TeslaMotors</td>\n",
       "      <td>ie4b81w</td>\n",
       "      <td>Is this with the unreleased beta software? I’m...</td>\n",
       "      <td>1.656459e+09</td>\n",
       "      <td>t3_vn0xq2</td>\n",
       "      <td>2022-06-29 01:24:55</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.778,...</td>\n",
       "      <td>[('NEG', 0.7782235741615295), ('NEU', 0.215484...</td>\n",
       "      <td>-0.771931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165106</th>\n",
       "      <td>TeslaMotors</td>\n",
       "      <td>ie4bcyt</td>\n",
       "      <td>No still 10.12.2. Just in another vehicle.</td>\n",
       "      <td>1.656459e+09</td>\n",
       "      <td>t3_vn0yi6</td>\n",
       "      <td>2022-06-29 01:25:58</td>\n",
       "      <td>AnalyzerOutput(output=NEU, probas={NEU: 0.973,...</td>\n",
       "      <td>[('NEG', 0.015009327791631222), ('NEU', 0.9726...</td>\n",
       "      <td>-0.002637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165107</th>\n",
       "      <td>TeslaMotors</td>\n",
       "      <td>ie4betk</td>\n",
       "      <td>Also wondering this question, would love to re...</td>\n",
       "      <td>1.656459e+09</td>\n",
       "      <td>t3_vn0ysw</td>\n",
       "      <td>2022-06-29 01:26:22</td>\n",
       "      <td>AnalyzerOutput(output=NEU, probas={NEU: 0.719,...</td>\n",
       "      <td>[('NEG', 0.0524548701941967), ('NEU', 0.719225...</td>\n",
       "      <td>0.175865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165108</th>\n",
       "      <td>TeslaMotors</td>\n",
       "      <td>ie4nqju</td>\n",
       "      <td>Looks like a bunch of companies are all releas...</td>\n",
       "      <td>1.656465e+09</td>\n",
       "      <td>t3_vn0ysw</td>\n",
       "      <td>2022-06-29 03:03:36</td>\n",
       "      <td>AnalyzerOutput(output=NEU, probas={NEU: 0.903,...</td>\n",
       "      <td>[('NEG', 0.005526799242943525), ('NEU', 0.9028...</td>\n",
       "      <td>0.086061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165109</th>\n",
       "      <td>TeslaMotors</td>\n",
       "      <td>ie5dkhc</td>\n",
       "      <td>I am an auto enthusiast myself, but this is ju...</td>\n",
       "      <td>1.656478e+09</td>\n",
       "      <td>t3_vn0ysw</td>\n",
       "      <td>2022-06-29 06:48:50</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.975,...</td>\n",
       "      <td>[('NEG', 0.9749175906181335), ('NEU', 0.022336...</td>\n",
       "      <td>-0.972172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>165110 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          subreddit       id  \\\n",
       "0       TeslaMotors  hqqtbh2   \n",
       "1       TeslaMotors  hqqtz7i   \n",
       "2       TeslaMotors  hqqu7z3   \n",
       "3       TeslaMotors  hqqxko8   \n",
       "4       TeslaMotors  hqr8kka   \n",
       "...             ...      ...   \n",
       "165105  TeslaMotors  ie4b81w   \n",
       "165106  TeslaMotors  ie4bcyt   \n",
       "165107  TeslaMotors  ie4betk   \n",
       "165108  TeslaMotors  ie4nqju   \n",
       "165109  TeslaMotors  ie5dkhc   \n",
       "\n",
       "                                                     body   created_utc  \\\n",
       "0       If help is needed, use our stickied support th...  1.640994e+09   \n",
       "1       Requirements: \\n\\n• Fits under the aero cover ...  1.640995e+09   \n",
       "2                       Photo credit @rkaplan1 on Twitter  1.640995e+09   \n",
       "3       I've wanted an Apple MagSafe charger in my cen...  1.640996e+09   \n",
       "4                I see you set your temperature to: NICE.  1.641002e+09   \n",
       "...                                                   ...           ...   \n",
       "165105  Is this with the unreleased beta software? I’m...  1.656459e+09   \n",
       "165106         No still 10.12.2. Just in another vehicle.  1.656459e+09   \n",
       "165107  Also wondering this question, would love to re...  1.656459e+09   \n",
       "165108  Looks like a bunch of companies are all releas...  1.656465e+09   \n",
       "165109  I am an auto enthusiast myself, but this is ju...  1.656478e+09   \n",
       "\n",
       "        parent_id                 date  \\\n",
       "0       t3_rt6fwg  2022-01-01 00:46:50   \n",
       "1       t3_rt6j33  2022-01-01 00:51:46   \n",
       "2       t3_rt6kex  2022-01-01 00:53:37   \n",
       "3       t3_rt72vs  2022-01-01 01:20:13   \n",
       "4       t3_rt8o5j  2022-01-01 02:47:11   \n",
       "...           ...                  ...   \n",
       "165105  t3_vn0xq2  2022-06-29 01:24:55   \n",
       "165106  t3_vn0yi6  2022-06-29 01:25:58   \n",
       "165107  t3_vn0ysw  2022-06-29 01:26:22   \n",
       "165108  t3_vn0ysw  2022-06-29 03:03:36   \n",
       "165109  t3_vn0ysw  2022-06-29 06:48:50   \n",
       "\n",
       "                                                  emotion  \\\n",
       "0       AnalyzerOutput(output=NEU, probas={NEU: 0.832,...   \n",
       "1       AnalyzerOutput(output=NEU, probas={NEU: 0.872,...   \n",
       "2       AnalyzerOutput(output=NEU, probas={NEU: 0.922,...   \n",
       "3       AnalyzerOutput(output=NEG, probas={NEG: 0.785,...   \n",
       "4       AnalyzerOutput(output=POS, probas={POS: 0.675,...   \n",
       "...                                                   ...   \n",
       "165105  AnalyzerOutput(output=NEG, probas={NEG: 0.778,...   \n",
       "165106  AnalyzerOutput(output=NEU, probas={NEU: 0.973,...   \n",
       "165107  AnalyzerOutput(output=NEU, probas={NEU: 0.719,...   \n",
       "165108  AnalyzerOutput(output=NEU, probas={NEU: 0.903,...   \n",
       "165109  AnalyzerOutput(output=NEG, probas={NEG: 0.975,...   \n",
       "\n",
       "                                                   probas  reg_output  \n",
       "0       [('NEG', 0.0038293171674013138), ('NEU', 0.832...    0.159910  \n",
       "1       [('NEG', 0.11134149879217148), ('NEU', 0.87199...   -0.094674  \n",
       "2       [('NEG', 0.003630931256338954), ('NEU', 0.9218...    0.070899  \n",
       "3       [('NEG', 0.784606397151947), ('NEU', 0.2061541...   -0.775367  \n",
       "4       [('NEG', 0.00296275457367301), ('NEU', 0.32224...    0.671825  \n",
       "...                                                   ...         ...  \n",
       "165105  [('NEG', 0.7782235741615295), ('NEU', 0.215484...   -0.771931  \n",
       "165106  [('NEG', 0.015009327791631222), ('NEU', 0.9726...   -0.002637  \n",
       "165107  [('NEG', 0.0524548701941967), ('NEU', 0.719225...    0.175865  \n",
       "165108  [('NEG', 0.005526799242943525), ('NEU', 0.9028...    0.086061  \n",
       "165109  [('NEG', 0.9749175906181335), ('NEU', 0.022336...   -0.972172  \n",
       "\n",
       "[165110 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 165110 entries, 0 to 165109\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   subreddit    165110 non-null  object \n",
      " 1   id           165110 non-null  object \n",
      " 2   body         165110 non-null  object \n",
      " 3   created_utc  165110 non-null  float64\n",
      " 4   parent_id    165110 non-null  object \n",
      " 5   date         165110 non-null  object \n",
      " 6   emotion      165110 non-null  object \n",
      " 7   probas       165110 non-null  object \n",
      " 8   reg_output   165110 non-null  float64\n",
      "dtypes: float64(2), object(7)\n",
      "memory usage: 11.3+ MB\n"
     ]
    }
   ],
   "source": [
    "#We have to figure oiut if the date column is already in datetime or not \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turns out it is not so we convert it \n",
    "df['date'] = pd.to_datetime(df['date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalized the dates, so that it fits with the garch model. So that we do not have information spillover to the day we are trying to forecast.\n",
    "df['date'] = df['date'].apply(lambda x: x.date() if x.time() < pd.Timestamp('14:30:00').time() else x.date() + pd.Timedelta(days=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maart\\AppData\\Local\\Temp\\ipykernel_13812\\906970833.py:2: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df = df.groupby(pd.Grouper(key='date', freq='D')).sum().reset_index()\n"
     ]
    }
   ],
   "source": [
    "## group the data by day and sum the 'reg_output' scores\n",
    "df = df.groupby(pd.Grouper(key='date', freq='D')).sum().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>reg_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>3.446126e+10</td>\n",
       "      <td>3.023068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>5.038161e+11</td>\n",
       "      <td>-4.589049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>1.381857e+12</td>\n",
       "      <td>-51.048246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>6.302370e+11</td>\n",
       "      <td>-38.858170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-05</td>\n",
       "      <td>1.590453e+12</td>\n",
       "      <td>-211.422332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>2023-02-12</td>\n",
       "      <td>1.508548e+10</td>\n",
       "      <td>0.423312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>2023-02-13</td>\n",
       "      <td>5.028688e+09</td>\n",
       "      <td>-1.824124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>2023-02-14</td>\n",
       "      <td>1.676336e+09</td>\n",
       "      <td>0.990002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>2023-02-15</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>2023-02-16</td>\n",
       "      <td>1.676507e+09</td>\n",
       "      <td>-0.918593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>412 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date   created_utc  reg_output\n",
       "0   2022-01-01  3.446126e+10    3.023068\n",
       "1   2022-01-02  5.038161e+11   -4.589049\n",
       "2   2022-01-03  1.381857e+12  -51.048246\n",
       "3   2022-01-04  6.302370e+11  -38.858170\n",
       "4   2022-01-05  1.590453e+12 -211.422332\n",
       "..         ...           ...         ...\n",
       "407 2023-02-12  1.508548e+10    0.423312\n",
       "408 2023-02-13  5.028688e+09   -1.824124\n",
       "409 2023-02-14  1.676336e+09    0.990002\n",
       "410 2023-02-15  0.000000e+00    0.000000\n",
       "411 2023-02-16  1.676507e+09   -0.918593\n",
       "\n",
       "[412 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group the data by day and calculate the average of 'reg_output' scores\n",
    "df = df.groupby(pd.Grouper(key='date', freq='D')).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>reg_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>3.446126e+10</td>\n",
       "      <td>3.023068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>5.038161e+11</td>\n",
       "      <td>-4.589049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>1.381857e+12</td>\n",
       "      <td>-51.048246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>6.302370e+11</td>\n",
       "      <td>-38.858170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-05</td>\n",
       "      <td>1.590453e+12</td>\n",
       "      <td>-211.422332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>2023-02-12</td>\n",
       "      <td>1.508548e+10</td>\n",
       "      <td>0.423312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>2023-02-13</td>\n",
       "      <td>5.028688e+09</td>\n",
       "      <td>-1.824124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>2023-02-14</td>\n",
       "      <td>1.676336e+09</td>\n",
       "      <td>0.990002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>2023-02-15</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>2023-02-16</td>\n",
       "      <td>1.676507e+09</td>\n",
       "      <td>-0.918593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>412 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date   created_utc  reg_output\n",
       "0   2022-01-01  3.446126e+10    3.023068\n",
       "1   2022-01-02  5.038161e+11   -4.589049\n",
       "2   2022-01-03  1.381857e+12  -51.048246\n",
       "3   2022-01-04  6.302370e+11  -38.858170\n",
       "4   2022-01-05  1.590453e+12 -211.422332\n",
       "..         ...           ...         ...\n",
       "407 2023-02-12  1.508548e+10    0.423312\n",
       "408 2023-02-13  5.028688e+09   -1.824124\n",
       "409 2023-02-14  1.676336e+09    0.990002\n",
       "410 2023-02-15  0.000000e+00    0.000000\n",
       "411 2023-02-16  1.676507e+09   -0.918593\n",
       "\n",
       "[412 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ASSUMPTION IS THAT IF THERE ARE NO COMMENTS, THEY ARE NEUTRAL. SO WE ASSUME IT HAS 0 IMPACT  \n",
    "#For some of the days we dont have comments, so we convert those NAN's into 0's, since we cannot calculate with NANS, since it has no numerical value. \n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group the data by day and aggeregate the comments to be one per day based on variance \n",
    "variance = df.groupby(pd.Grouper(key='date', freq='D'))['reg_output'].var().reset_index(name='variance')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we make sure that the number of reddit scores match with the number of stock prices, so that we have the same amount of frequencies \n",
    "merged_df = pd.merge(TSLA, df, on='date', how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>date</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>reg_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-03-01</td>\n",
       "      <td>382.583344</td>\n",
       "      <td>400.356659</td>\n",
       "      <td>378.679993</td>\n",
       "      <td>399.926666</td>\n",
       "      <td>399.926666</td>\n",
       "      <td>103931400</td>\n",
       "      <td>2022-03-01</td>\n",
       "      <td>8.592573e+11</td>\n",
       "      <td>-45.021069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>396.516663</td>\n",
       "      <td>402.666656</td>\n",
       "      <td>374.350006</td>\n",
       "      <td>383.196655</td>\n",
       "      <td>383.196655</td>\n",
       "      <td>100248300</td>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>6.397203e+11</td>\n",
       "      <td>-74.651293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-05-01</td>\n",
       "      <td>382.216675</td>\n",
       "      <td>390.113342</td>\n",
       "      <td>360.336670</td>\n",
       "      <td>362.706665</td>\n",
       "      <td>362.706665</td>\n",
       "      <td>80119800</td>\n",
       "      <td>2022-05-01</td>\n",
       "      <td>9.231118e+11</td>\n",
       "      <td>-81.385434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-06-01</td>\n",
       "      <td>359.000000</td>\n",
       "      <td>362.666656</td>\n",
       "      <td>340.166656</td>\n",
       "      <td>354.899994</td>\n",
       "      <td>354.899994</td>\n",
       "      <td>90336600</td>\n",
       "      <td>2022-06-01</td>\n",
       "      <td>1.290148e+12</td>\n",
       "      <td>-66.700095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>360.123322</td>\n",
       "      <td>360.309998</td>\n",
       "      <td>336.666656</td>\n",
       "      <td>342.320007</td>\n",
       "      <td>342.320007</td>\n",
       "      <td>84164700</td>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>4.969864e+10</td>\n",
       "      <td>-2.570915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>2022-12-23</td>\n",
       "      <td>126.370003</td>\n",
       "      <td>128.619995</td>\n",
       "      <td>121.019997</td>\n",
       "      <td>123.150002</td>\n",
       "      <td>123.150002</td>\n",
       "      <td>166989700</td>\n",
       "      <td>2022-12-23</td>\n",
       "      <td>1.003047e+11</td>\n",
       "      <td>-0.610287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>2022-12-27</td>\n",
       "      <td>117.500000</td>\n",
       "      <td>119.669998</td>\n",
       "      <td>108.760002</td>\n",
       "      <td>109.099998</td>\n",
       "      <td>109.099998</td>\n",
       "      <td>208643400</td>\n",
       "      <td>2022-12-27</td>\n",
       "      <td>4.180253e+10</td>\n",
       "      <td>0.251494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>2022-12-28</td>\n",
       "      <td>110.349998</td>\n",
       "      <td>116.269997</td>\n",
       "      <td>108.239998</td>\n",
       "      <td>112.709999</td>\n",
       "      <td>112.709999</td>\n",
       "      <td>221070500</td>\n",
       "      <td>2022-12-28</td>\n",
       "      <td>4.013230e+10</td>\n",
       "      <td>-2.641652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>120.389999</td>\n",
       "      <td>123.570000</td>\n",
       "      <td>117.500000</td>\n",
       "      <td>121.820000</td>\n",
       "      <td>121.820000</td>\n",
       "      <td>221923300</td>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>3.344532e+10</td>\n",
       "      <td>0.335976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>119.949997</td>\n",
       "      <td>124.480003</td>\n",
       "      <td>119.750000</td>\n",
       "      <td>123.180000</td>\n",
       "      <td>123.180000</td>\n",
       "      <td>157304500</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>3.679178e+10</td>\n",
       "      <td>-2.281908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>251 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date        Open        High         Low       Close   Adj Close  \\\n",
       "0   2022-03-01  382.583344  400.356659  378.679993  399.926666  399.926666   \n",
       "1   2022-04-01  396.516663  402.666656  374.350006  383.196655  383.196655   \n",
       "2   2022-05-01  382.216675  390.113342  360.336670  362.706665  362.706665   \n",
       "3   2022-06-01  359.000000  362.666656  340.166656  354.899994  354.899994   \n",
       "4   2022-07-01  360.123322  360.309998  336.666656  342.320007  342.320007   \n",
       "..         ...         ...         ...         ...         ...         ...   \n",
       "246 2022-12-23  126.370003  128.619995  121.019997  123.150002  123.150002   \n",
       "247 2022-12-27  117.500000  119.669998  108.760002  109.099998  109.099998   \n",
       "248 2022-12-28  110.349998  116.269997  108.239998  112.709999  112.709999   \n",
       "249 2022-12-29  120.389999  123.570000  117.500000  121.820000  121.820000   \n",
       "250 2022-12-30  119.949997  124.480003  119.750000  123.180000  123.180000   \n",
       "\n",
       "        Volume       date   created_utc  reg_output  \n",
       "0    103931400 2022-03-01  8.592573e+11  -45.021069  \n",
       "1    100248300 2022-04-01  6.397203e+11  -74.651293  \n",
       "2     80119800 2022-05-01  9.231118e+11  -81.385434  \n",
       "3     90336600 2022-06-01  1.290148e+12  -66.700095  \n",
       "4     84164700 2022-07-01  4.969864e+10   -2.570915  \n",
       "..         ...        ...           ...         ...  \n",
       "246  166989700 2022-12-23  1.003047e+11   -0.610287  \n",
       "247  208643400 2022-12-27  4.180253e+10    0.251494  \n",
       "248  221070500 2022-12-28  4.013230e+10   -2.641652  \n",
       "249  221923300 2022-12-29  3.344532e+10    0.335976  \n",
       "250  157304500 2022-12-30  3.679178e+10   -2.281908  \n",
       "\n",
       "[251 rows x 10 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.drop(['date', 'created_utc', 'Volume', 'Close', 'Low', 'High', 'Open', 'Date'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>reg_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>399.926666</td>\n",
       "      <td>-45.021069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>383.196655</td>\n",
       "      <td>-74.651293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>362.706665</td>\n",
       "      <td>-81.385434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>354.899994</td>\n",
       "      <td>-66.700095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>342.320007</td>\n",
       "      <td>-2.570915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>123.150002</td>\n",
       "      <td>-0.610287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>109.099998</td>\n",
       "      <td>0.251494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>112.709999</td>\n",
       "      <td>-2.641652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>121.820000</td>\n",
       "      <td>0.335976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>123.180000</td>\n",
       "      <td>-2.281908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>251 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Adj Close  reg_output\n",
       "0    399.926666  -45.021069\n",
       "1    383.196655  -74.651293\n",
       "2    362.706665  -81.385434\n",
       "3    354.899994  -66.700095\n",
       "4    342.320007   -2.570915\n",
       "..          ...         ...\n",
       "246  123.150002   -0.610287\n",
       "247  109.099998    0.251494\n",
       "248  112.709999   -2.641652\n",
       "249  121.820000    0.335976\n",
       "250  123.180000   -2.281908\n",
       "\n",
       "[251 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we have the final output, that can be used for volatility forecasting\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adj Close     0\n",
       "reg_output    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('SP_SC.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Volatility ; Data Science Way "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data into a pandas dataframe\n",
    "merged_df = pd.read_csv('SP_SC.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the returns and log returns\n",
    "merged_df['Returns'] = merged_df['Adj Close'].pct_change()\n",
    "merged_df['Log_Returns'] = np.log(1 + merged_df['Returns'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a synthetic target variable by calculating the rolling standard deviation of log returns\n",
    "merged_df['Volatility'] = merged_df['Log_Returns'].rolling(window=30).std() * np.sqrt(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the rows with missing values\n",
    "merged_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input and output variables\n",
    "X = merged_df[['Adj Close', 'reg_output']].values\n",
    "y = merged_df['Volatility'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "train_size = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the input data to fit the LSTM input shape\n",
    "X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mse', optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model on the training data\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test), verbose=2, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean squared error of the predictions\n",
    "mse = np.mean((y_pred - y_test)**2)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the root mean squared error\n",
    "rmse = np.sqrt(mse)\n",
    "print('RMSE: ', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reshape the original y_test and y_pred arrays to match the original shape\n",
    "y_test_orig = y_test.reshape(-1)\n",
    "y_pred_orig = y_pred.reshape(-1)\n",
    "\n",
    "# plot the predicted vs. actual volatility values\n",
    "plt.plot(y_test_orig, label='Actual')\n",
    "plt.plot(y_pred_orig, label='Predicted')\n",
    "plt.legend()\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Volatility')\n",
    "plt.title('Actual vs. Predicted Volatility')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data into a pandas dataframe\n",
    "merged_df = pd.read_csv('SP_SC.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the returns and log returns\n",
    "merged_df['Returns'] = merged_df['Adj Close'].pct_change()\n",
    "merged_df['Log_Returns'] = np.log(1 + merged_df['Returns'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a synthetic target variable by calculating the rolling standard deviation of log returns\n",
    "merged_df['Volatility'] = merged_df['Log_Returns'].rolling(window=30).std() * np.sqrt(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the rows with missing values\n",
    "merged_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "mm = MinMaxScaler()\n",
    "ss = StandardScaler()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['reg_output_sc']= ss.fit_transform(merged_df['reg_output']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input and output variables\n",
    "X = merged_df[['Adj Close', 'reg_output']].values\n",
    "y = merged_df['Volatility'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split the data into training and testing sets\n",
    "# train_size = int(len(X) * 0.8)\n",
    "# X_train, X_test = X[:train_size], X[train_size:]\n",
    "# y_train, y_test = y[:train_size], y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = y_train.reshape(y_train.shape[0], y_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test = y_test.reshape(y_test.shape[0], y_test.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Reshape the input data to fit the LSTM input shape\n",
    "# X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "# X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "train_data = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
    "test_data = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=1, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LSTM model\n",
    "# Define the input size, hidden size and number of outputs\n",
    "input_size = 2\n",
    "hidden_size = 16\n",
    "output_size = 1\n",
    "num_epochs= 10\n",
    "# Define the LSTM model and Linear output fully connected layer\n",
    "lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(lstm.parameters(), lr=0.0007)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Training Shape\", X_train.shape, y_train.shape)\n",
    "print(\"Testing Shape\", X_test.shape, y_test.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing Hyperparameters\n",
    "num_epochs = 100\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "# Loop over the number of epochs\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0\n",
    "    # Initialize the hidden state and the cell state\n",
    "    # The hidden state and the cell state reset to zero for every epoch\n",
    "    hs = torch.zeros(1, hidden_size)\n",
    "    cs = torch.zeros(1, hidden_size)\n",
    "\n",
    "    # Get the input and target at position i\n",
    "    for i, (data, label) in enumerate(train_loader):\n",
    "        \n",
    "        hidden = (hs, cs)\n",
    "        # Run the forward pass\n",
    "        output, hidden = lstm(data.float(), hidden)\n",
    "        output = fc(hidden[-1])\n",
    "\n",
    "        hs = hs.detach()\n",
    "        cs = cs.detach()\n",
    "\n",
    "        # 2. Network Evaluation\n",
    "        loss = criterion(output, label.float())\n",
    "\n",
    "        # 3. Gradient Calculation\n",
    "        loss.backward()\n",
    "\n",
    "        # 4. Back Propagation\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # Calculate the average training loss\n",
    "    train_loss = train_loss / len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "# Plot the MSE loss for each epoch\n",
    "plt.plot(train_losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.title('Training Loss over Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate the LSTM model\n",
    "mse = 0\n",
    "#By wrapping the evaluation code in a with torch.no_grad() context, \n",
    "#you can avoid unnecessary memory usage and speed up the evaluation process.\n",
    "with torch.no_grad():\n",
    "    # Initialize the hidden state and the cell state\n",
    "    # The hidden state and the cell state reset to zero for every epoch\n",
    "    hs = torch.zeros(1, hidden_size)\n",
    "    cs = torch.zeros(1, hidden_size)\n",
    "\n",
    "    for data, label in test_loader:\n",
    "        hidden = (hs, cs)\n",
    "        output, hidden = lstm(data.float(), hidden)\n",
    "        output = fc(hidden[-1])\n",
    "        hs = hs.detach()\n",
    "        cs = cs.detach()\n",
    "        \n",
    "        mse += ((output - label)**2).mean().item()\n",
    "\n",
    "mse /= len(test_loader)\n",
    "print('Test MSE: {}'.format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_list = []\n",
    "\n",
    "# Initialize the hidden state and the cell state\n",
    "# The hidden state and the cell state reset to zero for every epoch\n",
    "hs = torch.zeros(1, hidden_size)\n",
    "cs = torch.zeros(1, hidden_size)\n",
    "\n",
    "    \n",
    "for i, (data, label) in enumerate(train_loader):\n",
    "    output_list.append(0)\n",
    "    \n",
    "for i, (data, label) in enumerate(test_loader):\n",
    "    hidden = (hs, cs)\n",
    "    \n",
    "    # Run the forward pass\n",
    "    output, hidden = lstm(data.float(), hidden)\n",
    "    output = fc(hidden[-1])\n",
    "    hs = hs.detach()\n",
    "    cs = cs.detach()\n",
    "    output_list.append(output.detach().numpy()[0][0])\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataY_plot = list(y)\n",
    "data_predict = output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train_predict = lstm(X_ss)#forward pass\n",
    "# data_predict = train_predict.data.numpy() #numpy conversion\n",
    "# dataY_plot = y.Volume.values\n",
    "data_predict = output_list\n",
    "\n",
    "# data_predict = mm.inverse_transform([output_list]) #reverse transformation\n",
    "# dataY_plot = mm.inverse_transform(dataY_plot)\n",
    "plt.figure(figsize=(10,6)) #plotting\n",
    "plt.axvline(x=175, c='r', linestyle='--') #size of the training set\n",
    "\n",
    "plt.plot(dataY_plot, label='Actual Data') #actual plot\n",
    "plt.plot(data_predict, label='Predicted Data') #predicted plot\n",
    "plt.title('Time-Series Prediction')\n",
    "plt.legend()\n",
    "plt.show() \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_list = []\n",
    "\n",
    "# Initialize the hidden state and the cell state\n",
    "# The hidden state and the cell state reset to zero for every epoch\n",
    "hs = torch.zeros(1, hidden_size)\n",
    "cs = torch.zeros(1, hidden_size)\n",
    "for i, (data, label) in enumerate(test_loader):\n",
    "    hidden = (hs, cs)\n",
    "    \n",
    "    # Run the forward pass\n",
    "    output, hidden = lstm(data.float(), hidden)\n",
    "    output = fc(hidden[-1])\n",
    "    hs = hs.detach()\n",
    "    cs = cs.detach()\n",
    "    output_list.append(output.detach().numpy()[0][0])\n",
    "    \n",
    "for i, (data, label) in enumerate(train_loader):\n",
    "    hidden = (hs, cs)\n",
    "\n",
    "    # Run the forward pass\n",
    "    output, hidden = lstm(data.float(), hidden)\n",
    "    output = fc(hidden[-1])\n",
    "    hs = hs.detach()\n",
    "    cs = cs.detach()\n",
    "    output_list.append(output.detach().numpy()[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataY_plot = list(y)\n",
    "data_predict = output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train_predict = lstm(X_ss)#forward pass\n",
    "# data_predict = train_predict.data.numpy() #numpy conversion\n",
    "# dataY_plot = y.Volume.values\n",
    "data_predict = output_list\n",
    "\n",
    "# data_predict = mm.inverse_transform([output_list]) #reverse transformation\n",
    "# dataY_plot = mm.inverse_transform(dataY_plot)\n",
    "plt.figure(figsize=(10,6)) #plotting\n",
    "plt.axvline(x=200, c='r', linestyle='--') #size of the training set\n",
    "\n",
    "plt.plot(dataY_plot, label='Actual Data') #actual plot\n",
    "plt.plot(data_predict, label='Predicted Data') #predicted plot\n",
    "plt.title('Time-Series Prediction')\n",
    "plt.legend()\n",
    "plt.show() \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the trained RNN model\n",
    "torch.save(lstm.state_dict(), 'lstm.pt')\n",
    "\n",
    "# Load the model\n",
    "rnn = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "rnn.load_state_dict(torch.load('lstm.pt'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81f0f7e7cc12f2c94950a8a01991b2436cc0c748747074750516e2585d64b449"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
