{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reference for where i got most of the code from https://www.askpython.com/python/examples/reddit-web-scraper-in-python\n",
    "import pandas as pd\n",
    "import praw\n",
    "from praw.models import MoreComments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_authorized = praw.Reddit(client_id=\"ZeCMY9LXRnsY9M78sS8uGg\", \n",
    "                                client_secret=\"V-MS7rfVXCJMWLvTfGNyjLLC85ycSg\",\n",
    "                                user_agent=\"my-app\",\n",
    "                                username=\"ForThethesis\",\n",
    "                                password=\"ThePassword123\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_subreddit = input(\"Enter The Name Of Subreddit :\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Display Name: wallstreetbets\n",
      "Title: wallstreetbets\n",
      "Description: Our official Twitter: [@Official_WSB](https://twitter.com/official_wsb)\n",
      "\n",
      "---\n",
      "\n",
      "The rules and submission guidelines are maintained on new Reddit so be sure to check them and make sure you're up to date.\n",
      "\n",
      "* Read the [rules](https://www.reddit.com/r/wallstreetbets/about/rules)\n",
      "\n",
      "* Read the [comment and submission guide](https://www.reddit.com/r/wallstreetbets/wiki/contentguide)\n",
      "\n",
      "* Read the [FAQ](https://www.reddit.com/r/wallstreetbets/wiki/faq) if you're new to both wallstreetbets and trading.\n",
      "\n",
      "---\n",
      "**Join the discord**\n",
      "\n",
      "[WSB Discord](https://discord.gg/wsbverse)\n",
      "\n",
      "**filter by flairs**\n",
      "\n",
      "^Navigate ^WSB |^We ^recommend ^best ^daily ^DD\n",
      ":--|:--     \n",
      "**DD** | [All](https://ns.reddit.com/r/wallstreetbets/search?sort=new&restrict_sr=on&q=flair%3ADD) / [**Best Daily**](https://ns.reddit.com/r/wallstreetbets/search?sort=top&q=flair%3ADD&restrict_sr=on&t=day) / [Best Weekly](https://ns.reddit.com/r/wallstreetbets/search?sort=top&q=flair%3ADD&restrict_sr=on&t=week)\n",
      "**Discussion** | [All](https://ns.reddit.com/r/wallstreetbets/search?sort=new&restrict_sr=on&q=flair%3ADiscussion) / [**Best Daily**](https://ns.reddit.com/r/wallstreetbets/search?sort=top&q=flair%3ADiscussion&restrict_sr=on&t=day) / [Best Weekly](https://ns.reddit.com/r/wallstreetbets/search?sort=top&q=flair%3ADiscussion&restrict_sr=on&t=week)\n",
      "**YOLO** | [All](https://ns.reddit.com/r/wallstreetbets/search?sort=new&restrict_sr=on&q=flair%3AYOLO) / [**Best Daily**](https://ns.reddit.com/r/wallstreetbets/search?sort=top&q=flair%3AYOLO&restrict_sr=on&t=day) / [Best Weekly](https://ns.reddit.com/r/wallstreetbets/search?sort=top&q=flair%3AYOLO&restrict_sr=on&t=week)\n",
      "**Gain** | [All](https://ns.reddit.com/r/wallstreetbets/search?sort=new&restrict_sr=on&q=flair%3AGain) / [**Best Daily**](https://ns.reddit.com/r/wallstreetbets/search?sort=top&q=flair%3AGain&restrict_sr=on&t=day) / [Best Weekly](https://ns.reddit.com/r/wallstreetbets/search?sort=top&q=flair%3AGain&restrict_sr=on&t=week)\n",
      "**Loss** | [All](https://ns.reddit.com/r/wallstreetbets/search?sort=new&restrict_sr=on&q=flair%3ALoss) / [**Best Daily**](https://ns.reddit.com/r/wallstreetbets/search?sort=top&q=flair%3ALoss&restrict_sr=on&t=day) / [Best Weekly](https://ns.reddit.com/r/wallstreetbets/search?sort=top&q=flair%3ALoss&restrict_sr=on&t=week)\n",
      "**Shitpost** | [All](https://ns.reddit.com/r/wallstreetbets/search?sort=new&restrict_sr=on&q=flair%3AShitpost) / [**Best Daily**](https://ns.reddit.com/r/wallstreetbets/search?sort=top&q=flair%3AShitpost&restrict_sr=on&t=day) / [Best Weekly](https://ns.reddit.com/r/wallstreetbets/search?sort=top&q=flair%3AShitpost&restrict_sr=on&t=week)\n",
      "**Meme** | [All](https://ns.reddit.com/r/wallstreetbets/search?sort=new&restrict_sr=on&q=flair%3AMeme) / [**Best Daily**](https://ns.reddit.com/r/wallstreetbets/search?sort=top&q=flair%3AMeme&restrict_sr=on&t=day) / [Best Weekly](https://ns.reddit.com/r/wallstreetbets/search?sort=top&q=flair%3AMeme&restrict_sr=on&t=week)\n",
      "**Storytime** | [All](https://ns.reddit.com/r/wallstreetbets/search?sort=new&restrict_sr=on&q=flair%3AStorytime) / [**Best Daily**](https://ns.reddit.com/r/wallstreetbets/search?sort=top&q=flair%3AStorytime&restrict_sr=on&t=day) / [Best Weekly](https://ns.reddit.com/r/wallstreetbets/search?sort=top&q=flair%3AStorytime&restrict_sr=on&t=week)\n",
      "**Satire** | [All](https://ns.reddit.com/r/wallstreetbets/search?sort=new&restrict_sr=on&q=flair%3ASatire) / [**Best Daily**](https://ns.reddit.com/r/wallstreetbets/search?sort=top&q=flair%3ASatire&restrict_sr=on&t=day) / [Best Weekly](https://ns.reddit.com/r/wallstreetbets/search?sort=top&q=flair%3ASatire&restrict_sr=on&t=week)\n",
      "**Options** | [All](https://ns.reddit.com/r/wallstreetbets/search?sort=new&restrict_sr=on&q=flair%3AOptions) / [**Best Daily**](https://ns.reddit.com/r/wallstreetbets/search?sort=top&q=flair%3AOptions&restrict_sr=on&t=day) / [Best Weekly](https://ns.reddit.com/r/wallstreetbets/search?sort=top&q=flair%3AOptions&restrict_sr=on&t=week)\n",
      "**Futures** | [All](https://ns.reddit.com/r/wallstreetbets/search?sort=new&restrict_sr=on&q=flair%3AFutures) / [**Best Daily**](https://ns.reddit.com/r/wallstreetbets/search?sort=top&q=flair%3AFutures&restrict_sr=on&t=day) / [Best Weekly](https://ns.reddit.com/r/wallstreetbets/search?sort=top&q=flair%3AFutures&restrict_sr=on&t=week)\n",
      "**Forex** | [All](https://ns.reddit.com/r/wallstreetbets/search?sort=new&restrict_sr=on&q=flair%3AForex) / [**Best Daily**](https://ns.reddit.com/r/wallstreetbets/search?sort=top&q=flair%3AForex&restrict_sr=on&t=day) / [Best Weekly](https://ns.reddit.com/r/wallstreetbets/search?sort=top&q=flair%3AForex&restrict_sr=on&t=week)\n",
      "**Stocks** | [All](https://ns.reddit.com/r/wallstreetbets/search?sort=new&restrict_sr=on&q=flair%3AStocks) / [**Best Daily**](https://ns.reddit.com/r/wallstreetbets/search?sort=top&q=flair%3AStocks&restrict_sr=on&t=day) / [Best Weekly](https://ns.reddit.com/r/wallstreetbets/search?sort=top&q=flair%3AStocks&restrict_sr=on&t=week)\n",
      "**Fundamentals** | [All](https://ns.reddit.com/r/wallstreetbets/search?sort=new&restrict_sr=on&q=flair%3AFundamentals) / [**Best Daily**](https://ns.reddit.com/r/wallstreetbets/search?sort=top&q=flair%3AFundamentals&restrict_sr=on&t=day) / [Best Weekly](https://ns.reddit.com/r/wallstreetbets/search?sort=top&q=flair%3AFundamentals&restrict_sr=on&t=week)\n",
      "**Technicals** | [All](https://ns.reddit.com/r/wallstreetbets/search?sort=new&restrict_sr=on&q=flair%3ATechnicals) / [**Best Daily**](https://ns.reddit.com/r/wallstreetbets/search?sort=top&q=flair%3ATechnicals&restrict_sr=on&t=day) / [Best Weekly](https://ns.reddit.com/r/wallstreetbets/search?sort=top&q=flair%3ATechnicals&restrict_sr=on&t=week)\n",
      "\n",
      "\n",
      "[Earnings Thread](https://reddit.com/r/wallstreetbets/search?sort=new&restrict_sr=on&q=flair%3A\"Earnings%20Thread\") - [Daily Thread](https://reddit.com/r/wallstreetbets/search?sort=new&restrict_sr=on&q=flair%3A\"Daily%20Discussion\")\n",
      "\n",
      "---\n",
      "\n",
      "**Market Trading Hours**\n",
      "\n",
      "|Exchange|Open|Close|\n",
      "|:-------:|--------:|--------:|\n",
      "|[Frankfurt](http://goo.gl/9teCjs) | 9:00 AM | 8:00 PM | \n",
      "|[New York](https://goo.gl/eODOhO) | 9:30 AM  | 4:00 PM|\n",
      "|[CME](http://goo.gl/VZZDPg) | 5:00 PM | 4:15 PM |\n",
      "|[CBOE](http://goo.gl/fMSNBY) | 8:30 AM | 3:15 PM  |\n",
      "|[Tokyo](http://goo.gl/Aiwygk) | 9:00 AM | 3:00 PM  |\n",
      "|[Hong Kong](http://goo.gl/vLR2vh) | 9:30 AM | 4:00 PM  |\n",
      "* Hours respective to their own timezone.\n",
      "\n",
      "[^^source](https://goo.gl/hk9CB4)\n"
     ]
    }
   ],
   "source": [
    "subreddit = reddit_authorized.subreddit(name_subreddit)\n",
    "print(\"Display Name:\", subreddit.display_name)\n",
    "print(\"Title:\", subreddit.title)\n",
    "print(\"Description:\", subreddit.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maart\\AppData\\Local\\Temp\\ipykernel_64468\\1053530738.py:1: DeprecationWarning: Positional arguments for 'BaseListingMixin.top' will no longer be supported in PRAW 8.\n",
      "Call this function with 'time_filter' as a keyword argument.\n",
      "  posts = subreddit.top(\"week\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of posts extracted :  100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Total Comments</th>\n",
       "      <th>Post URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>if JPow gives up trying to correct asset (real...</td>\n",
       "      <td>960</td>\n",
       "      <td>https://i.redd.it/hbzppwtsbnfa1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thanks, Dave</td>\n",
       "      <td>1028</td>\n",
       "      <td>https://i.redd.it/p5uo6fadbcfa1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Enough of the bears enough of the bulls I'm re...</td>\n",
       "      <td>580</td>\n",
       "      <td>https://i.redd.it/nhms8vjvoega1.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NFLX SEP 15 '23 190 PUT</td>\n",
       "      <td>575</td>\n",
       "      <td>https://i.redd.it/u4i1w78o90ga1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Someone sent me this from some motivational in...</td>\n",
       "      <td>2365</td>\n",
       "      <td>https://i.redd.it/nrs1vtbbpcga1.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  Total Comments  \\\n",
       "0  if JPow gives up trying to correct asset (real...             960   \n",
       "1                                       Thanks, Dave            1028   \n",
       "2  Enough of the bears enough of the bulls I'm re...             580   \n",
       "3                            NFLX SEP 15 '23 190 PUT             575   \n",
       "4  Someone sent me this from some motivational in...            2365   \n",
       "\n",
       "                              Post URL  \n",
       "0  https://i.redd.it/hbzppwtsbnfa1.jpg  \n",
       "1  https://i.redd.it/p5uo6fadbcfa1.jpg  \n",
       "2  https://i.redd.it/nhms8vjvoega1.png  \n",
       "3  https://i.redd.it/u4i1w78o90ga1.jpg  \n",
       "4  https://i.redd.it/nrs1vtbbpcga1.jpg  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts = subreddit.top(\"week\")\n",
    " \n",
    "posts_dict = {\"Title\": [],\n",
    "              \"Total Comments\": [],\n",
    "              \"Post URL\": []}\n",
    " \n",
    "for post in posts:\n",
    "    posts_dict[\"Title\"].append(post.title)\n",
    "    posts_dict[\"Total Comments\"].append(post.num_comments)\n",
    "    posts_dict[\"Post URL\"].append(post.url)\n",
    " \n",
    "top_posts_week = pd.DataFrame(posts_dict)\n",
    " \n",
    "print(\"Number of posts extracted : \",top_posts_week.shape[0])\n",
    "top_posts_week.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maart\\AppData\\Local\\Temp\\ipykernel_64468\\3355089070.py:1: DeprecationWarning: Positional arguments for 'BaseListingMixin.top' will no longer be supported in PRAW 8.\n",
      "Call this function with 'time_filter' as a keyword argument.\n",
      "  posts = subreddit.top(\"month\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of posts extracted :  100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Total Comments</th>\n",
       "      <th>Post URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Google is doing layoffs</td>\n",
       "      <td>5719</td>\n",
       "      <td>https://v.redd.it/zvsa581ncuda1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Short Airbnb Inc???</td>\n",
       "      <td>2445</td>\n",
       "      <td>https://i.redd.it/eshco93192fa1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>if JPow gives up trying to correct asset (real...</td>\n",
       "      <td>960</td>\n",
       "      <td>https://i.redd.it/hbzppwtsbnfa1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pelosi strikes again</td>\n",
       "      <td>2075</td>\n",
       "      <td>https://www.reddit.com/gallery/10l98o3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thanks, Dave</td>\n",
       "      <td>1028</td>\n",
       "      <td>https://i.redd.it/p5uo6fadbcfa1.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  Total Comments  \\\n",
       "0                            Google is doing layoffs            5719   \n",
       "1                                Short Airbnb Inc???            2445   \n",
       "2  if JPow gives up trying to correct asset (real...             960   \n",
       "3                               Pelosi strikes again            2075   \n",
       "4                                       Thanks, Dave            1028   \n",
       "\n",
       "                                 Post URL  \n",
       "0         https://v.redd.it/zvsa581ncuda1  \n",
       "1     https://i.redd.it/eshco93192fa1.jpg  \n",
       "2     https://i.redd.it/hbzppwtsbnfa1.jpg  \n",
       "3  https://www.reddit.com/gallery/10l98o3  \n",
       "4     https://i.redd.it/p5uo6fadbcfa1.jpg  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts = subreddit.top(\"month\")\n",
    " \n",
    "posts_dict = {\"Title\": [],\n",
    "              \"Total Comments\": [],\n",
    "              \"Post URL\": []}\n",
    " \n",
    "for post in posts:\n",
    "    posts_dict[\"Title\"].append(post.title)\n",
    "    posts_dict[\"Total Comments\"].append(post.num_comments)\n",
    "    posts_dict[\"Post URL\"].append(post.url)\n",
    " \n",
    "top_posts_month = pd.DataFrame(posts_dict)\n",
    " \n",
    "print(\"Number of posts extracted : \",top_posts_month.shape[0])\n",
    "top_posts_month.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maart\\AppData\\Local\\Temp\\ipykernel_64468\\653019308.py:1: DeprecationWarning: Positional arguments for 'BaseListingMixin.top' will no longer be supported in PRAW 8.\n",
      "Call this function with 'time_filter' as a keyword argument.\n",
      "  posts = subreddit.top(\"year\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of posts extracted :  100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Total Comments</th>\n",
       "      <th>Post URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>🔮WallStreetBets Predictions Tournament for Feb...</td>\n",
       "      <td>358</td>\n",
       "      <td>https://reddit.com/r/wallstreetbets/prediction...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Discord Chat For Billionaires [part 1]</td>\n",
       "      <td>754</td>\n",
       "      <td>https://v.redd.it/hfwvjpn81gg81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charlie Munger is doubling down on $BABA sayin...</td>\n",
       "      <td>1281</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wish me luck retards</td>\n",
       "      <td>1522</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Roblox earnings is next week and Nancy Pelosi ...</td>\n",
       "      <td>934</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  Total Comments  \\\n",
       "0  🔮WallStreetBets Predictions Tournament for Feb...             358   \n",
       "1             Discord Chat For Billionaires [part 1]             754   \n",
       "2  Charlie Munger is doubling down on $BABA sayin...            1281   \n",
       "3                               Wish me luck retards            1522   \n",
       "4  Roblox earnings is next week and Nancy Pelosi ...             934   \n",
       "\n",
       "                                            Post URL  \n",
       "0  https://reddit.com/r/wallstreetbets/prediction...  \n",
       "1                    https://v.redd.it/hfwvjpn81gg81  \n",
       "2  https://www.reddit.com/r/wallstreetbets/commen...  \n",
       "3  https://www.reddit.com/r/wallstreetbets/commen...  \n",
       "4  https://www.reddit.com/r/wallstreetbets/commen...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts = subreddit.top(\"year\")\n",
    " \n",
    "posts_dict = {\"Title\": [],\n",
    "              \"Total Comments\": [],\n",
    "              \"Post URL\": []}\n",
    " \n",
    "for post in posts:\n",
    "    posts_dict[\"Title\"].append(post.title)\n",
    "    posts_dict[\"Total Comments\"].append(post.num_comments)\n",
    "    posts_dict[\"Post URL\"].append(post.url)\n",
    " \n",
    "top_posts_year = pd.DataFrame(posts_dict)\n",
    " \n",
    "print(\"Number of posts extracted : \",top_posts_year.shape[0])\n",
    "top_posts_year.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'comments'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [28], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m submission \u001b[39m=\u001b[39m reddit_authorized\u001b[39m.\u001b[39msubmission\n\u001b[0;32m      4\u001b[0m post_comments \u001b[39m=\u001b[39m []\n\u001b[1;32m----> 5\u001b[0m \u001b[39mfor\u001b[39;00m comment \u001b[39min\u001b[39;00m submission\u001b[39m.\u001b[39mcomments:\n\u001b[0;32m      6\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(comment) \u001b[39m==\u001b[39m MoreComments:\n\u001b[0;32m      7\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'comments'"
     ]
    }
   ],
   "source": [
    "url = top_posts_month['Post URL'][0]\n",
    "submission = reddit_authorized.submission(url=url)\n",
    " \n",
    "post_comments = []\n",
    "for comment in submission.comments:\n",
    "    if type(comment) == MoreComments:\n",
    "        continue\n",
    "    post_comments.append(comment.body)\n",
    " \n",
    "comments_df = pd.DataFrame(post_comments, columns=['comment'])\n",
    " \n",
    "print(\"Number of Comments : \",comments_df.shape[0])\n",
    "comments_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "19f9ddf3622c0b1569490fd927172cf777b9021a692f6f37361c5e5933f47574"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
